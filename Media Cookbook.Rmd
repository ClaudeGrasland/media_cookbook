--- 
title: "The media cookbook"
subtitle: "Working paper of the ANR-DFG Imageun Project"
author: "Claude Grasland"
date: "`r Sys.Date()`"
documentclass: book
link-citations: yes
description: "A reminder of some experiments made in 2021"
site: bookdown::bookdown_site
always_allow_html: yes
---
--- 
title: "The media cookbook"
subtitle: "Working paper of the ANR-DFG Imageun Project"
author: "Claude Grasland"
date: "`r Sys.Date()`"
documentclass: book
link-citations: yes
description: "A reminder of some experiments made in 2021"
site: bookdown::bookdown_site
always_allow_html: yes
---

```{r setup, include = FALSE, cache = FALSE}
library(knitr)
library(tidyverse)

knitr::opts_chunk$set(cache = TRUE,
                      echo = TRUE,
                      comment = "")

```



# Introduction

The aim of this cookbook is to exchange ideas and programs between members of the "Media Group" of the ANR-DFG project IMAGEUN. 


<!--chapter:end:index.Rmd-->


# Import from Media Cloud {#c11_mediacloud}

Placeholder


## Selection of media with source manager
## Checking the stability through time
## Selection of news specifically related to a topic (option)
## Download and storage of news

<!--chapter:end:11-corpus-mediacloud.Rmd-->


# quanteda corpus {#c12_mediacloud_to_quanteda}

Placeholder


## Example 
### Importation of text to R
### encoding problems
### Transformation in quanteda format
### Storage of the quanteda object
### Backtransformation of quanteda to data.table or tibble
## Germany
### Frankfurter Allgemeine Zeitung 
### Süddeutsche Zeitung
## France
### Le Figaro
### Le Monde
## Royaume-Uni
### The Guardian
### The Daily Telegraph
## Ireland
### The Irish Time
### The Belfast Telegraph
## Turkey
### The Yeni Sati
### Cumhuryet
## Tunisia
### Réalités
### L'économiste Maghrebin
### La Presse
### Babnet
## Algeria
### Al Nahar
### El Kahber
### El Watan

<!--chapter:end:12-mediacloud_to_quanteda.Rmd-->


# Wikidata {#c21_wikidata}

Placeholder


## Introduction
## Wikidata 
### Codification of entities
### Informations on entities
### Wikipedia entities as nodes of an ontolongy
### A tool for cross-linguistical experiments
## The package WikidataR
### Basic operations
#### identification of entities of interest
### Elaboration of a cross_linguistic dictionnary
### Extraction of aliases
### Conclusion

<!--chapter:end:21-Wikidata.Rmd-->


# Dictionary of geographical entities {#c22_Dicogeo}

Placeholder


## Dictionary of geographical entities
### Load the list of world regions, organisation states and capital cities
### Extract définitions
### Extract aliases and create dictionary

<!--chapter:end:22-Dicogeo.Rmd-->


# Geographical tags {#c23_taggeo}

Placeholder


## Manual correctio n of dictionnary
## Detection of geographical entities
### Le Figaro (FRA)
### Le Monde
### FAZ
### Süddeutsche Zeitung
### Guardian
### Daily Telegraph
### Belfast Telegraph
### Irish Times
### Cumhuryet
### Yeni Safak
### Al Nahar (DZA)
### El Khabar (DZA)
### Global corpus

<!--chapter:end:23-Taggeo.Rmd-->

# Frequencye {#c24_frequency}

```{r}
library(knitr)
library(dplyr)
library(quanteda)
library(data.table)
library(tidytext)
library(ggplot2)
```

## Objectives

The aim of this section is to separate states and world region and to evaluate the relative frequencies of wrold regions by media an through time.



## Prepare data


```{r, warning=F, eval=FALSE}
qd<-readRDS("quanteda/corpus_worldgeo_V2.RDS")
qd$regs<-qd$tags
qd$regs<-gsub("ST_...","",qd$tags)
qd$regs<-gsub("CA_...","",qd$regs)
qd$nbregs<-ntoken(tokens(as.character(qd$regs)))
td<-tidy(qd)



hypercube <-function(qd = qd,
                     when = "date",
                     when_cut = "year",
                     who = "source",
                     where1 = "tags",
                     where2 = "tags")
                     
  {   

# create data.table accroding to parameter chosen
  don<-docvars(qd)

  df<-data.table(id = docid(qd),
                 who = don[,who],
                 when = as.character(cut(don[,when],breaks=when_cut)),
                 where1 = don[,where1],
                 where2 = don[,where2])



# add code _no_ for empty fields
df$where1[df$where1==""]<-"_no_"
df$where2[df$where2==""]<-"_no_"


# unnest where1
  df<-unnest_tokens(df,where1,where1,to_lower=F)
  
# unnest where2
  df<-unnest_tokens(df,where2,where2,to_lower=F)  
  
# define number of occurence by id
  nb<-df[,.N,list(id)] %>%  mutate(wgt = 1/N) %>% select(-N)
  df<-df %>% left_join(nb) 
  
  rm(nb)
 
# Aggregate
  hc<- df[,.( tags = .N, news=sum(wgt)) ,.(who, when,where1,where2)]
  
# Convert date to time
  hc$when<-as.Date(hc$when)
  
# return hypercube
  return(hc)

}

hc_reg <- hypercube(qd = qd,
                     when = "date",
                     when_cut = "months",
                     who = "source",
                     where1 = "regs",
                     where2 = "regs")

saveRDS(hc_reg,"hypercube/hc_reg.RDS")
```
## Distribution des nouvelles par média au cours du temps

```{r, warnings=F, message=FALSE}
hc_reg<-readRDS("hypercube/hc_reg.RDS")

hc_reg$OK<-as.factor(hc_reg$where1!="_no_") 
levels(hc_reg$OK)<-c("Non","Oui")

month<-hc_reg[,.(nb<-sum(news)),.(when,who,OK)] %>%
  dcast(formula = who+when~OK, value.var = "V1",fill = 0) %>%
  mutate(Media=who,
         Date = when,
         Total=Non+Oui,
         Frequence = Oui,
         Pourcentage = 100*Frequence/Total) %>%
  select(Media,Date, Total,Frequence, Pourcentage) %>%
  filter(is.na(Date)==F, Date < as.Date("2021-07-01"))


#kable(month,digits=c(0,0,0,2),caption = "Parts des nouvelles mentionnant une macro-région")

ggplot(month,aes(x=Date,y=Total,color=Media)) + 
       geom_line(lwd=0.5) +

ggtitle("Nombre de nouvelles par média (Jan. 2019-  Juin 2021)",
               subtitle = "source : Mediacloud)" )
```





## Fréquences des macro-régions par journal

```{r, warnings=F, message=FALSE}
hc_reg<-readRDS("hypercube/hc_reg.RDS")

hc_reg$OK<-as.factor(hc_reg$where1!="_no_") 
levels(hc_reg$OK)<-c("Non","Oui")

med<-hc_reg[,.(nb<-sum(news)),.(who,OK)] %>%
  dcast(formula = who~OK, value.var = "V1") %>% 
  mutate(Media = who,
         Total=Non+Oui,
         Frequence = Oui,
         Pourcentage = 100*Frequence/Total) %>%
  select(Media, Total,Frequence, Pourcentage)

tot<-med[1,]
tot$Media<-"Total"
tot$Total<-sum(med$Total)
tot$Frequence<-sum(med$Frequence)
tot$Pourcentage<-100*tot$Frequence/tot$Total

tabres<-rbind(med,tot)
kable(tabres,digits=c(0,0,0,2),caption = "Parts des nouvelles mentionnant une macro-région")
```

-**Commentaire** : Sur un total de 916024 titres de nouvelles, 20619 contenaient au moins une macro-région, ce qui représente une proportion de 2.28% soit environ une nouvelle sur cinquante. Cette proportion varoe de 1 à 4% selon les journaux. 


## Fréquence des macro-régions par mois

```{r, warnings=F, message=FALSE}
hc_reg<-readRDS("hypercube/hc_reg.RDS")

hc_reg$OK<-as.factor(hc_reg$where1!="_no_") 
levels(hc_reg$OK)<-c("Non","Oui")

month<-hc_reg[,.(nb<-sum(news)),.(when,OK)] %>%
  dcast(formula = when~OK, value.var = "V1") %>% 
  mutate(Date = when,
         Total=Non+Oui,
         Frequence = Oui,
         Pourcentage = 100*Frequence/Total) %>%
  select(Date, Total,Frequence, Pourcentage) %>%
  filter(is.na(Date)==F, Date < as.Date("2021-07-01"))


kable(month,digits=c(0,0,0,2),caption = "Parts des nouvelles mentionnant une macro-région")

ggplot(month,aes(x=Date,y=Pourcentage)) + 
       geom_line(col="red",lwd=0.5) +
       geom_point(col="black") +
       geom_smooth() +
       ggtitle("Les macro-régions dans les nouvelles de presse quotienne (Jan. 2019-  Juin 2021)",
               subtitle = "12 médias de France, Allemagne, Turquie, Tunisie, Irlande et Royaume-Uni (source : Mediacloud)" )
```

## Distribution des nouvelles sur les macro-régions par média au cours du temps

```{r, warnings=F, message=FALSE}
hc_reg<-readRDS("hypercube/hc_reg.RDS")

hc_reg$OK<-as.factor(hc_reg$where1!="_no_") 
levels(hc_reg$OK)<-c("Non","Oui")

month<-hc_reg[,.(nb<-sum(news)),.(when,who,OK)] %>%
  dcast(formula = who+when~OK, value.var = "V1",fill = 0) %>%
  mutate(Media=who,
         Date = when,
         Total=Non+Oui,
         Frequence = Oui,
         Pourcentage = 100*Frequence/Total) %>%
  select(Media,Date, Total,Frequence, Pourcentage) %>%
  filter(is.na(Date)==F, Date < as.Date("2021-07-01"))


#kable(month,digits=c(0,0,0,2),caption = "Parts des nouvelles mentionnant une macro-région")

ggplot(month,aes(x=Date,y=Pourcentage,color=Media)) + 
       geom_smooth(lwd=0.6,fill=NA) +

ggtitle("Part des nouvelles sur les macro-régions par média (Jan. 2019-  Juin 2021)",
               subtitle = "source : Mediacloud" )
```

<!--chapter:end:24-Frequency.Rmd-->


# Hypercube {#c24_hypercube}

Placeholder


## Objectives
## Prepare data
### Load corpus
### Load hypercube function
### Create Hypercube
### Load Wikidata entity names
## Geographical entities
### Which % of news ?
### Which entities are the most mentionned ?
### Top non state entities by media

<!--chapter:end:30-Hypercube.Rmd-->


# Cybergeo {#c31_cybergeo}

Placeholder


## Introduction
## Top macro-regions
### Data aggregation
### Top 50 regions in full corpus
### German newspapers - Top 10 regions
### French newspapers - Top 10 regions
### UK newspapers - Top 10 regions
### Irish newspapers - Top 10 regions
### Turkish newspapers - Top 10 regions
### Algerian newspapers
## Synthesis  
### Factor 1-2
### Factors 3-4
### Cluster analysis(world regions)
### Cluster analysis (medias)
## Specific vocabulary
### Europe/EU (Q46 / Q458)
### Mediterranea (Q4918)

<!--chapter:end:41-Cybergeo.Rmd-->

