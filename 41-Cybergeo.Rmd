# Cybergeo {#c31_cybergeo}

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE)
library(knitr)
library(tidytext, quietly = TRUE)
library(dplyr, quietly=TRUE)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textmodels)
library(stringr)
library(data.table)
library(FactoMineR)
```


## Introduction

We analyze macroregions throughon a **selection of 110 entities** :

1.  65 entities related to **continent and "natural" Earth divisions** :

-   *continents* : Asia, Africa, Europa, ...
-   *subcontinents* : North Africa, Western Europe,..
-   *peninsula/ archipel/ ...* : Scandinavia, Caraïbes, ...
-   *bioclimatic area* : Sahara, Amazonia, Sahel
-   *mountains/plain/...* : Alps, Balkans, Ands, ...
-   *Oceans/Seas/Gulf* : Atlantic, Arctic, Mediterranea, ...

2.  45 **regional organizations** mentionned by Wikimedia : NATO, EU, CEI, NAFTA, ...

Warning : This analysis does not offer perfect guarantee of quality because :

1.  The list of entities has not been validated by the IMAGEUN's partners
2.  The dictionary established in the different languages has not been controled by native speakers


We use  a corpus of text where target wikipedia entities has been recognized. Xe keep only world regions and we eliminate the states

```{r, warning=F}

qd<-readRDS("quanteda/corpus_worldgeo_V2.RDS")
qd<-corpus_subset(qd,nbtags>0)

qd$regs<-gsub("ST_...","",qd$tags)
qd$regs<-gsub("CA_...","",qd$regs)
qd$nbregs<-ntoken(tokens(as.character(qd$regs)))
qd<-corpus_subset(qd,nbregs>0)

td<-tidy(qd)
td <-td[order(td$nbregs,decreasing = T),c(1,2,3,6,7)]
kable(td[c(1,2,5,7),])

reg_def<-readRDS("dict/worldgeo_def_V1.RDS")
tab_def<-reg_def %>% filter(lang=="fr") %>% select(code,type,label)

#Simplify label
tab_def$label[tab_def$code=="OR_NATO"]<-"OTAN"

#reg_def<-reg_def[complete.cases(reg_def),]
#reg_def<-unique(reg_def)
#tab_def<-dcast(reg_def, formula = code~lang, value.var="label")
#tab_def<-tab_def[ ,-c(2)]
#kable(head(tab_def))

```



## Top macro-regions


### Data aggregation

For the experience 2, we create a new object called **hypercube** where the text of news has been removed and where we keep only the number of *tags* or proportion of *news* speaking from one or several regions (*where1*, *where2*), by media (*who*) and by time period (*when*)

```{r}


hypercube <-function(qd = qd,
                     when = "date",
                     when_cut = "year",
                     who = "source",
                     where1 = "tags",
                     where2 = "tags")
                     
  {   

# create data.table accroding to parameter chosen
  don<-docvars(qd)

  df<-data.table(id = docid(qd),
                 who = don[,who],
                 when = as.character(cut(don[,when],breaks=when_cut)),
                 where1 = don[,where1],
                 where2 = don[,where2])



# add code _no_ for empty fields
df$where1[df$where1==""]<-"_no_"
df$where2[df$where2==""]<-"_no_"


# unnest where1
  df<-unnest_tokens(df,where1,where1,to_lower=F)
  
# unnest where2
  df<-unnest_tokens(df,where2,where2,to_lower=F)  
  
# define number of occurence by id
  nb<-df[,.N,list(id)] %>%  mutate(wgt = 1/N) %>% select(-N)
  df<-df %>% left_join(nb) 
  
  rm(nb)
 
# Aggregate
  hc<- df[,.( tags = .N, news=sum(wgt)) ,.(who, when,where1,where2)]
  
# Convert date to time
  hc$when<-as.Date(hc$when)
  
# return hypercube
  return(hc)

}



hc_reg <- hypercube(qd = qd,
                     when = "date",
                     when_cut = "year",
                     who = "source",
                     where1 = "regs",
                     where2 = "regs")

# filter problematic entities
eliminate<-c("CO_AFR_south")
hc_reg<-hc_reg[!(where1 %in% eliminate),]


#reg_def<-readRDS("dict/worldreg003_def.RDS")
#tab_def<-dcast(reg_def, formula =id~lang, value.var="label")
#tab_def<-tab_def[ ,-c(2)]
#kable(head(tab_def))

```

### Top 50 regions in full corpus

We can propose firstly a table of top entities in the whole corpus of newspapers.

```{r}

# Compute
df<-hc_reg[where1 !="_no_",list(nb = sum(news)), list(where1)] 
df<-merge(tab_def,df,by.x="code",by.y="where1",all.x=F,all.y=T)
df<-df[order(df$nb, decreasing = T),]
row.names(df)<-1:dim(df)[1]

kable(head(df,50), digits=0,row.names = T)
```
The frequence of each region is measured in index 100 equal to the most mentionned region. 



### German newspapers - Top 10 regions

```{r}

# Compute
df<-hc_reg[where1 !="_no_",list(nb = sum(news)), list(who, where1)] %>% 
     group_by(who) %>%
     filter(where1 != "Q828")%>%
     mutate(pct = 100*nb/max(nb),
            rnk = rank(-nb))

df_sel <- df %>% filter(substr(who,4,6)=="DEU", rnk < 11)
df_sel<-merge(df_sel,tab_def,by.x="where1",by.y="code")

res <- df_sel %>% filter(rnk < 11) %>% select(who, rnk,label, pct) %>% mutate(who=substr(who,4,12))
res<-res[order(res$who, res$rnk),]
tab1<-res[1:10,2]
names(tab1) <- c("Rank")
tab2<-res[1:10,c(3,4)]
names(tab2)<-c(paste("FAZ","Region",sep="_"),paste("FAZ","pct",sep=" "))
tab3<-res[11:20,c(3,4)]
names(tab3)<-c(paste("Süd. Zeit.","Region",sep="_"),paste("Süd. Zeit.","pct",sep=" "))
tab<-cbind(tab1,tab2,tab3)

kable(tab,digits=1, row.names = F)

```

### French newspapers - Top 10 regions

```{r}

# Compute
df<-hc_reg[where1 !="_no_",list(nb = sum(news)), list(who, where1)] %>% 
     group_by(who) %>%
     filter(where1 != "Q828")%>%
     mutate(pct = 100*nb/max(nb),
            rnk = rank(-nb))

df_sel <- df %>% filter(substr(who,4,6)=="FRA", rnk < 11)
df_sel<-merge(df_sel,tab_def,by.x="where1",by.y="code")

res <- df_sel %>% filter(rnk < 11) %>% select(who, rnk,label, pct) %>% mutate(who=substr(who,4,12))
res<-res[order(res$who, res$rnk),]
tab1<-res[1:10,2]
names(tab1) <- c("Rank")
tab2<-res[1:10,c(3,4)]
names(tab2)<-c(paste("Figaro","Region",sep="_"),paste("Figaro","pct",sep=" "))
tab3<-res[11:20,c(3,4)]
names(tab3)<-c(paste("Le Monde","Region",sep="_"),paste("Le Monde","pct",sep=" "))
tab<-cbind(tab1,tab2,tab3)

kable(tab,digits=1, row.names = F)

```

### UK newspapers - Top 10 regions

```{r}

# Compute
df<-hc_reg[where1 !="_no_",list(nb = sum(news)), list(who, where1)] %>% 
     group_by(who) %>%
     filter(where1 != "Q828")%>%
     mutate(pct = 100*nb/max(nb),
            rnk = rank(-nb))

df_sel <- df %>% filter(substr(who,4,6)=="GBR", rnk < 11)
df_sel<-merge(df_sel,tab_def,by.x="where1",by.y="code")

res <- df_sel %>% filter(rnk < 11) %>% select(who, rnk,label, pct) %>% mutate(who=substr(who,4,12))
res<-res[order(res$who, res$rnk),]
tab1<-res[1:10,2]
names(tab1) <- c("Rank")
tab2<-res[1:10,c(3,4)]
names(tab2)<-c(paste("Guardian","Region",sep="_"),paste("Guardian","pct",sep=" "))
tab3<-res[11:20,c(3,4)]
names(tab3)<-c(paste("Daily Telegraph","Region",sep="_"),paste("Daily Telegraph","pct",sep=" "))
tab<-cbind(tab1,tab2,tab3)

kable(tab,digits=1, row.names = F)

```

### Irish newspapers - Top 10 regions

```{r}

# Compute
df<-hc_reg[where1 !="_no_",list(nb = sum(news)), list(who, where1)] %>% 
     group_by(who) %>%
     filter(where1 != "Q828")%>%
     mutate(pct = 100*nb/max(nb),
            rnk = rank(-nb))

df_sel <- df %>% filter(substr(who,4,6) %in% c("IRL","NIR"), rnk < 11)
df_sel<-merge(df_sel,tab_def,by.x="where1",by.y="code")

res <- df_sel %>% filter(rnk < 11) %>% select(who, rnk,label, pct) %>% mutate(who=substr(who,4,12))
res<-res[order(res$who, res$rnk),]
tab1<-res[1:10,2]
names(tab1) <- c("Rank")
tab2<-res[1:10,c(3,4)]
names(tab2)<-c(paste("Irish Times","Region",sep="_"),paste("Irish Times","pct",sep=" "))
tab3<-res[11:20,c(3,4)]
names(tab3)<-c(paste("Belfast Telegraph","Region",sep="_"),paste("Belfast Telegraph","pct",sep=" "))
tab<-cbind(tab1,tab2,tab3)

kable(tab,digits=1, row.names = F)

```





### Turkish newspapers - Top 10 regions


```{r}

# Compute
df<-hc_reg[where1 !="_no_",list(nb = sum(news)), list(who, where1)] %>% 
     group_by(who) %>%
#     filter(where1 != "Q828")%>%
     mutate(pct = 100*nb/max(nb),
            rnk = rank(-nb))

df_sel <- df %>% filter(substr(who,4,6)=="TUR", rnk < 11)
df_sel<-merge(df_sel,tab_def,by.x="where1",by.y="code")


res <- df_sel %>% filter(rnk < 11) %>% select(who, rnk,label, pct) %>% mutate(who=substr(who,4,12))
res<-res[order(res$who, res$rnk),]
tab1<-res[1:10,2]
names(tab1) <- c("Rank")
tab2<-res[1:10,c(3,4)]
names(tab2)<-c(paste("Cumhuryet","Region",sep="_"),paste("Cumhuryet","pct",sep=" "))
tab3<-res[11:20,c(3,4)]
names(tab3)<-c(paste("Yeni Savak","Region",sep="_"),paste("Yeni Savak","pct",sep=" "))
tab<-cbind(tab1,tab2,tab3)

kable(tab,digits=1, row.names = F)

```

### Algerian newspapers

```{r}

# Compute
df<-hc_reg[where1 !="_no_",list(nb = sum(news)), list(who, where1)] %>% 
     group_by(who) %>%
     filter(where1 != "Q828")%>%
     mutate(pct = 100*nb/max(nb),
            rnk = rank(-nb))

df_sel <- df %>% filter(substr(who,4,6)=="DZA", rnk < 11)
df_sel<-merge(df_sel,tab_def,by.x="where1",by.y="code")

res <- df_sel %>% filter(rnk < 11) %>% select(who, rnk,label, pct) %>% mutate(who=substr(who,4,12))
res<-res[order(res$who, res$rnk),]
tab1<-res[1:10,2]
names(tab1) <- c("Rank")
tab2<-res[1:10,c(3,4)]
names(tab2)<-c("Al Nahar (ar)","pct1")
tab3<-res[12:21,c(3,4)]
names(tab3)<-c("El Kahbar (ar)","pct2")


tab<-cbind(tab1,tab2,tab3)

kable(tab,digits=c(0,1,1,1,1,1), row.names = F)

```




## Synthesis  

### Factor 1-2


```{r}
# Matrix
reg_med <-hc_reg[where1 !="_no_",list(nb = sum(news)), list(where1, who)] %>%
  dcast(formula = where1~who, value.var = "nb",fill = 0)
mat<-as.matrix(reg_med[,-1])

# Labels
lab<-reg_med[,1] %>% rename(code=where1) %>% unique()
lab<-merge(lab,tab_def,all.x=T,all.y=F) %>% filter(duplicated(code)==F)
# Row.names (choose the language you want !)
row.names(mat)<-lab$label

# Filter ambiguous units
#mat<-mat[row.names(mat) != "Americas",]
#mat<-mat[row.names(mat) != "Asia Minor",]
#mat<-mat[row.names(mat) != "Southern Africa",]
#mat<-mat[row.names(mat) != "Europe",]
#mat<-mat[row.names(mat) != "European Union",]


# Select units > 20
sel<-mat[apply(mat,1,sum)>20,]

# Exclude units mentionned by less than 3 media
sel <- sel[apply(sel>0,1,sum)>1,]


afc <- CA(sel, graph = F)
#library(explor)
#explor(afc)

res <- explor::prepare_results(afc)
explor::CA_var_plot(res, xax = 1, yax = 2, lev_sup = FALSE, var_sup = FALSE,
    var_sup_choice = , var_hide = "None", var_lab_min_contrib = 0, col_var = "Position",
    symbol_var = NULL, size_var = "Contrib", size_range = c(52.5, 700), labels_size = 8,
    point_size = 56, transitions = TRUE, labels_positions = "auto", xlim = c(-2,
        1), ylim = c(-1, 2.1))

```

### Factors 3-4

```{r}
res <- explor::prepare_results(afc)
explor::CA_var_plot(res, xax = 3, yax = 4, lev_sup = FALSE, var_sup = FALSE,
    var_sup_choice = , var_hide = "None", var_lab_min_contrib = 0, col_var = "Position",
    symbol_var = NULL, size_var = "Contrib", size_range = c(52.5, 700), labels_size = 8,
    point_size = 56, transitions = TRUE, labels_positions = "auto", xlim = c(-2.17,
        1.7), ylim = c(-1.86, 2.01))
```

### Cluster analysis(world regions)

```{r}
cah1 <- HCPC(afc,nb.clust = 5,graph = FALSE)
plot.HCPC(cah1,choice="tree")
```

### Cluster analysis (medias)

```{r}
cah2 <- HCPC(afc,nb.clust = 6,graph = FALSE,cluster.CA = "columns")
plot.HCPC(cah2,choice="tree")
```

## Specific vocabulary

### Europe/EU (Q46 / Q458)

```{r, out.width="40%"}
ent = c("OR_EU", "CO_EUR")

qd2<-corpus_subset(qd,str_count(regs,ent)>0 ) 


lang="fr"
country = "FRA"
mystop="french"
sel<-corpus_subset(qd2, substr(source,1,2)==lang & substr(source,4,6) %in% country  )
toks <- sel %>%
    tokens(remove_punct = TRUE) %>%
   tokens_split(separator="'") %>%
    tokens_remove(pattern = stopwords(mystop), padding = FALSE) %>%
     tokens_select(min_nchar = 3)
fcmat <- fcm(toks, context = "window", tri = FALSE)
feat <- names(topfeatures(fcmat, 30))
fcm_select(fcmat, pattern = feat) %>%
    textplot_network(min_freq = 0.2) 



lang="de"
country="DEU"
mystop="german"
year=2019
sel<-corpus_subset(qd2, substr(source,1,2)==lang & substr(source,4,6) == country  )
toks <- sel %>%
    tokens(remove_punct = TRUE) %>%
   tokens_split(separator="'") %>%
    tokens_remove(pattern = stopwords(mystop), padding = FALSE) %>%
     tokens_select(min_nchar = 3)
fcmat <- fcm(toks, context = "window", tri = FALSE)
feat <- names(topfeatures(fcmat, 30))
fcm_select(fcmat, pattern = feat) %>%
    textplot_network(min_freq = 0.2)

lang="ar"
country = "DZA"
mystop="french"
sel<-corpus_subset(qd2, substr(source,1,2)==lang & substr(source,4,6) %in% country  )
toks <- sel %>%
    tokens(remove_punct = TRUE) %>%
   tokens_split(separator="'") %>%
    tokens_remove(pattern = stopwords(mystop), padding = FALSE) %>%
     tokens_select(min_nchar = 3)
fcmat <- fcm(toks, context = "window", tri = FALSE)
feat <- names(topfeatures(fcmat, 30))
fcm_select(fcmat, pattern = feat) %>%
    textplot_network(min_freq = 0.2) 



lang="tr"
country="TUR"
mystop="french"
year= 2019

sel<-corpus_subset(qd2, substr(source,1,2)==lang & substr(source,4,6) == country )
toks <- sel %>%
    tokens(remove_punct = TRUE) %>%
   tokens_split(separator="'") %>%
    tokens_remove(pattern = stopwords(mystop), padding = FALSE) %>%
     tokens_select(min_nchar = 3)
fcmat <- fcm(toks, context = "window", tri = FALSE)
feat <- names(topfeatures(fcmat, 30))
fcm_select(fcmat, pattern = feat) %>%
    textplot_network(min_freq = 0.2)


```

### Mediterranea (Q4918)

```{r, out.width="40%"}
ent = "SE_medit"
qd2<-corpus_subset(qd,str_count(regs,ent)>0 ) 


lang="fr"
country = "FRA"
mystop="french"
sel<-corpus_subset(qd2, substr(source,1,2)==lang & substr(source,4,6) %in% country  )
toks <- sel %>%
    tokens(remove_punct = TRUE) %>%
   tokens_split(separator="'") %>%
    tokens_remove(pattern = stopwords(mystop), padding = FALSE) %>%
     tokens_select(min_nchar = 3)
fcmat <- fcm(toks, context = "window", tri = FALSE)
feat <- names(topfeatures(fcmat, 30))
fcm_select(fcmat, pattern = feat) %>%
    textplot_network(min_freq = 0.2)


lang="de"
country="DEU"
mystop="german"
sel<-corpus_subset(qd2, substr(source,1,2)==lang & substr(source,4,6) == country  )
toks <- sel %>%
    tokens(remove_punct = TRUE) %>%
   tokens_split(separator="'") %>%
    tokens_remove(pattern = stopwords(mystop), padding = FALSE) %>%
     tokens_select(min_nchar = 3)
fcmat <- fcm(toks, context = "window", tri = FALSE)
feat <- names(topfeatures(fcmat, 30))
fcm_select(fcmat, pattern = feat) %>%
    textplot_network(min_freq = 0.2)

lang="ar"
country = "DZA"
mystop="french"
sel<-corpus_subset(qd2, substr(source,1,2)==lang & substr(source,4,6) %in% country  )
toks <- sel %>%
    tokens(remove_punct = TRUE) %>%
   tokens_split(separator="'") %>%
    tokens_remove(pattern = stopwords(mystop), padding = FALSE) %>%
     tokens_select(min_nchar = 3)
fcmat <- fcm(toks, context = "window", tri = FALSE)
feat <- names(topfeatures(fcmat, 30))
fcm_select(fcmat, pattern = feat) %>%
    textplot_network(min_freq = 0.2) 



lang="tr"
country="TUR"
mystop="french"
year= 2019
sel<-corpus_subset(qd2, substr(source,1,2)==lang & substr(source,4,6) == country )
toks <- sel %>%
    tokens(remove_punct = TRUE) %>%
   tokens_split(separator="'") %>%
    tokens_remove(pattern = stopwords(mystop), padding = FALSE) %>%
     tokens_select(min_nchar = 3)
fcmat <- fcm(toks, context = "window", tri = FALSE)
feat <- names(topfeatures(fcmat, 30))
fcm_select(fcmat, pattern = feat) %>%
    textplot_network(min_freq = 0.2)


```
